{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bf4ae9-2953-4c03-820a-fc7e24195c51",
   "metadata": {},
   "source": [
    "### Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4903c76-b925-4e9e-bd28-bc13cbaa85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import random\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4747f8-fa23-48de-9a52-a3567107bc37",
   "metadata": {},
   "source": [
    "### Creación de Funciones Secundarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd29864-92d6-453c-b9a4-b0dd96ac3531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_id():\n",
    "    return str(uuid.uuid4())[:16]\n",
    "def get_random_categories(categories, num_records):\n",
    "    return np.random.choice(categories, num_records)\n",
    "def get_random_numbers(min_value, max_value, num_records):\n",
    "    return np.random.uniform(min_value, max_value, num_records)\n",
    "def get_foreign_values(foreign_df, foreign_column, num_records):\n",
    "    return np.random.choice(foreign_df[foreign_column].tolist(), num_records)\n",
    "\n",
    "def get_categorical_dataset_simulated(simulation_extended, category_cols, num_records):\n",
    "    category_values = [simulation_extended[col].unique() for col in category_cols]\n",
    "    combinations = list(product(*category_values))\n",
    "    simulated_data = np.random.choice(len(combinations), num_records)\n",
    "    simulated_df = pd.DataFrame([combinations[i] for i in simulated_data], columns=category_cols)\n",
    "    return simulated_df\n",
    "\n",
    "def get_numeric_column_simulated(simulated_df, simulation_extended, category_cols, numeric_col):\n",
    "    grouped_stats = simulation_extended.groupby(category_cols)[numeric_col].agg(['mean', 'std']).reset_index()\n",
    "    simulated_values = pd.merge(simulated_df, grouped_stats, on=category_cols, how='left')\n",
    "    \n",
    "    simulated_values[numeric_col] = simulated_values.apply(\n",
    "        lambda row: np.random.normal(row['mean'], row['std']), axis=1\n",
    "    )\n",
    "    \n",
    "    return simulated_values[[numeric_col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9658f85-ad37-4e2c-85c4-30f55ab17da6",
   "metadata": {},
   "source": [
    "### Creación de Función Build DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9187d1d-6442-40d3-bd33-97b956e7950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataframes(conf_list):\n",
    "    dfs = {}\n",
    "    pending = conf_list.copy()\n",
    "    processed = set()\n",
    "    \n",
    "    while pending:\n",
    "        for conf in pending:\n",
    "            can_process = True\n",
    "            for col in conf[\"columns\"]:\n",
    "                if col[\"type\"] == \"foreign\":\n",
    "                    foreign_dataset = col[\"values\"].split('.')[0]\n",
    "                    if foreign_dataset not in dfs:\n",
    "                        can_process = False\n",
    "                        break\n",
    "            \n",
    "            if can_process:\n",
    "                data = {}\n",
    "                num_records = conf.get(\"random_rows\", 1000)\n",
    "\n",
    "                for col in conf[\"columns\"]:\n",
    "                    col_type = col[\"type\"]\n",
    "                    col_name = col[\"name\"]\n",
    "\n",
    "                    if col_type == \"category\":\n",
    "                        data[col_name] = get_random_categories(col[\"values\"], num_records)\n",
    "                    elif col_type == \"numeric\":\n",
    "                        if \"std\" in col[\"values\"]:\n",
    "                            data[col_name] = np.random.normal(\n",
    "                                col[\"values\"][\"mean\"],\n",
    "                                col[\"values\"][\"std\"],\n",
    "                                num_records\n",
    "                            )\n",
    "                            data[col_name] = np.clip(data[col_name], col[\"values\"][\"min\"], col[\"values\"][\"max\"])\n",
    "                        else:\n",
    "                            data[col_name] = get_random_numbers(\n",
    "                                col[\"values\"][\"min\"],\n",
    "                                col[\"values\"][\"max\"],\n",
    "                                num_records\n",
    "                            )\n",
    "                    elif col_type == \"unique\":\n",
    "                        data[col_name] = [generate_unique_id() for _ in range(num_records)]\n",
    "                    elif col_type == \"foreign\":\n",
    "                        foreign_dataset, foreign_column = col[\"values\"].split('.')\n",
    "                        data[col_name] = get_foreign_values(dfs[foreign_dataset], foreign_column, num_records)\n",
    "\n",
    "                dfs[conf[\"ds\"]] = pd.DataFrame(data)\n",
    "                pending.remove(conf)\n",
    "                processed.add(conf[\"ds\"])\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb80a0-6622-4d8c-b64a-6183fe495a95",
   "metadata": {},
   "source": [
    "### Creación de Función de Análisis, Combinación y Extensión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b03551-d826-4d50-89da-e3be800c3a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_combinations_and_extend(dfs, conf_list):\n",
    "    for conf in conf_list:\n",
    "        df_name = conf[\"ds\"]\n",
    "        if df_name in dfs:\n",
    "            df = dfs[df_name]\n",
    "            for col in conf[\"columns\"]:\n",
    "                if col[\"type\"] == \"category\" and \"combinations\" in col:\n",
    "                    comb_columns = col[\"combinations\"]\n",
    "                    unique_combinations = pd.DataFrame(product(*(df[col].unique() for col in comb_columns)), columns=comb_columns)\n",
    "                    dfs[f\"{df_name}_combinations\"] = unique_combinations\n",
    "                    \n",
    "                    num_records = len(unique_combinations)\n",
    "                    extended_data = {}\n",
    "                    for col in conf[\"columns\"]:\n",
    "                        col_type = col[\"type\"]\n",
    "                        col_name = col[\"name\"]\n",
    "\n",
    "                        if col_type == \"category\" and col_name not in comb_columns:\n",
    "                            extended_data[col_name] = get_random_categories(col[\"values\"], num_records)\n",
    "                        elif col_type == \"numeric\":\n",
    "                            if \"std\" in col[\"values\"]:\n",
    "                                extended_data[col_name] = np.random.normal(\n",
    "                                    col[\"values\"][\"mean\"],\n",
    "                                    col[\"values\"][\"std\"],\n",
    "                                    num_records\n",
    "                                )\n",
    "                                extended_data[col_name] = np.clip(extended_data[col_name], col[\"values\"][\"min\"], col[\"values\"][\"max\"])\n",
    "                            else:\n",
    "                                extended_data[col_name] = get_random_numbers(\n",
    "                                    col[\"values\"][\"min\"],\n",
    "                                    col[\"values\"][\"max\"],\n",
    "                                    num_records\n",
    "                                )\n",
    "                        elif col_type == \"unique\":\n",
    "                            extended_data[col_name] = [generate_unique_id() for _ in range(num_records)]\n",
    "                        elif col_type == \"foreign\":\n",
    "                            foreign_dataset, foreign_column = col[\"values\"].split('.')\n",
    "                            extended_data[col_name] = get_foreign_values(dfs[foreign_dataset], foreign_column, num_records)\n",
    "                    \n",
    "                    extended_df = pd.DataFrame(extended_data)\n",
    "                    dfs[f\"{df_name}_extended\"] = pd.concat([unique_combinations, extended_df], axis=1)\n",
    "                    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8994b942-88bc-4bda-bf48-dd3ec7ffa843",
   "metadata": {},
   "source": [
    "### Configuración de Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "894dfedf-4bc2-4876-a1ff-b93e64589429",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {\n",
    "    \"ds\": \"dataset1\",\n",
    "    \"columns\": [\n",
    "        {\n",
    "            \"name\": \"area\",\n",
    "            \"type\": \"category\",\n",
    "            \"values\": [\"TI\", \"FIN\", \"HR\"],\n",
    "            \"combinations\": [\"area\"]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"id\",\n",
    "            \"type\": \"unique\"\n",
    "        }\n",
    "    ],\n",
    "    \"random\": False\n",
    "}\n",
    "\n",
    "d2 = {\n",
    "    \"ds\": \"dataset2\",\n",
    "    \"columns\": [\n",
    "        {\n",
    "            \"name\": \"id\",\n",
    "            \"type\": \"unique\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"area\",\n",
    "            \"type\": \"foreign\",\n",
    "            \"values\": \"dataset1.area\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"subarea\",\n",
    "            \"type\": \"category\",\n",
    "            \"values\": [\"SA1\", \"SA2\", \"SA3\", \"SA4\"],\n",
    "            \"combinations\": [\"area\", \"subarea\"]\n",
    "        }\n",
    "    ],\n",
    "    \"random\": False\n",
    "}\n",
    "\n",
    "d3 = {\n",
    "    \"ds\": \"dataset3\",\n",
    "    \"columns\": [\n",
    "        {\n",
    "            \"name\": \"id\",\n",
    "            \"type\": \"unique\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"subarea\",\n",
    "            \"type\": \"foreign\",\n",
    "            \"values\": \"dataset2.id\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"income\",\n",
    "            \"type\": \"numeric\",\n",
    "            \"values\": {\"min\": 20000, \"max\": 50000}\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"goal\",\n",
    "            \"type\": \"numeric\",\n",
    "            \"values\": {\"min\": 1000, \"max\": 10000, \"mean\": 5000, \"std\": 2000}\n",
    "        }\n",
    "    ],\n",
    "    \"random\": True,\n",
    "    \"random_rows\": 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab5510c-28d1-4f00-a95f-ff6595f133ee",
   "metadata": {},
   "source": [
    "### Ejecución de Funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ce20b9-5cfe-496a-a538-865073afd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_list = [d3, d1, d2]\n",
    "dataframes = build_dataframes(conf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "308d477d-c1a9-4ec9-b10e-18a9702c3162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                subarea        income          goal\n",
      "0      ef599f8f-cf3e-40  21586.243527   4276.901486\n",
      "1      282f081c-94fe-49  26013.667986   9329.122836\n",
      "2      de52ea12-b645-40  35126.067571   6789.263548\n",
      "3      123abb81-e4d7-44  21500.475467  14004.189674\n",
      "4      3d0c1004-fdf8-40           NaN           NaN\n",
      "...                 ...           ...           ...\n",
      "99995  92fca9ef-2e27-42  38903.366565   6350.042108\n",
      "99996  ef599f8f-cf3e-40  21403.577665   3081.976671\n",
      "99997  f54b78a2-6101-4b           NaN           NaN\n",
      "99998  bbcc083d-a1cd-48           NaN           NaN\n",
      "99999  4a3c458d-c30e-4d           NaN           NaN\n",
      "\n",
      "[100000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "simulation_extended = dataframes[\"dataset3\"]\n",
    "category_cols = [\"subarea\"]\n",
    "numeric_cols = [\"income\", \"goal\"]\n",
    "\n",
    "final_simulation = get_categorical_dataset_simulated(simulation_extended, category_cols, 100000)\n",
    "\n",
    "for nc in numeric_cols:\n",
    "    dfn = get_numeric_column_simulated(final_simulation, simulation_extended, category_cols, nc)\n",
    "    final_simulation = pd.merge(final_simulation, dfn[[nc]], left_index=True, right_index=True)\n",
    "\n",
    "print(final_simulation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
